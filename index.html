<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Abhijeet Nayak (Website under construction!!)</title>

  <meta name="author" content="Abhijeet Nayak">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">

</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p class="name" style="text-align: center;">
                    Abhijeet Nayak
                  </p>
                  <p>I am an ELLIS PhD student at the <a href="https://www.utn.de/departments/department-engineering/artificial-intelligence-and-robotics-lab/">University of Technology</a> in Nuremberg, 
                    under the supervision of Prof. <a href="https://www.utn.de/person/wolfram-burgard/">Wolfram Burgard</a>. 
                    My primary research focus is on applying foundation models to robotics, particularly in robot navigation and manipulation.
                 </p>  
                 <p>I earned my masterâ€™s degree in Computer Science from the <a href="https://uni-freiburg.de/en/">University of Freiburg</a>. 
                  During my time there, I worked with the <a href="https://rl.uni-freiburg.de/home-page">Robot Learning Lab</a> on radar localization using prior LiDAR maps. 
                  I also served as a research assistant with the <a href="https://lmb.informatik.uni-freiburg.de/">Computer Vision Group</a>, where I focused on object manipulation for robotic arms.
                </p>  
                <p>Prior to my master's studies, I was part of the vehicle localization team at <a href="https://www.mbrdi.co.in/#/">Mercedes-Benz R&D India</a>, developing lane-level localization algorithms 
                  for the <a href="https://www.mercedes-benz.de/passengercars/technology/drive-pilot.html?srsltid=AfmBOoprwXh1Ck8MTGp0OIoQ4byNklT6tLEYVq__NZG6f7xDBEDvw0Vw">Drive Pilot</a> system. 
                  These algorithms are now deployed in production-level Mercedes-Benz S-Class vehicles.
                </p>
                  <!-- <p>I'm a PhD student at the <a href="https://www.utn.de/departments/department-engineering/artificial-intelligence-and-robotics-lab/">University of Technology</a> in Nuremberg, where I am advised by <a
                      href="https://www.utn.de/person/wolfram-burgard/">Prof. Wolfram Burgard</a>.
                      My core interests lie at the use of foundation models for robotics applications.
                  </p>
                  <p>
                    I completed my master's degree in Computer Science at the <a href="https://uni-freiburg.de/en/">University of Freiburg</a>.
                    I was a part of the Robot Learning lab at Freiburg, where I worked on Radar localization against prior LiDAR maps.
                    I was also a part of the Computer Vision group at Freiburg as a research assistant. Here, I worked on object manipulation for robot arms.
                  </p>
                  <p>
                    Previously, I was a part of the vehcile localization team at Mercedes-Benz R&D India, where I worked
                    on lane-level localization for the Drive Pilot system. Our algorithms are currently in production level
                    Mercedes-Benz S-Class vehicles. -->


                  </p>
                  <p style="text-align:center">
                    <a href="mailto:abhijeetknayak@gmail.com">Email</a> &nbsp;/&nbsp;
                    <a href="data/CV.pdf">CV</a> &nbsp;/&nbsp;
                    <a href="https://linkedin.com/in/abhijeet-nayak-831abba7/">LinkedIn</a> &nbsp;/&nbsp;
                    <a href="https://scholar.google.at/citations?hl=de&user=EbabmYcAAAAJ">Scholar</a> &nbsp;/&nbsp;
                    <a href="https://github.com/abhijeetknayak/">GitHub</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/abhijeet.jpg"><img
                      style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo"
                      src="images/abhijeet.jpg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <h2>Research</h2>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>


              <tr onmouseout="flownav_stop()" onmouseover="flownav_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='flownav_image'><video width=100% height=100% muted autoplay loop>
                        <source src="videos/flownav.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                      </video></div>
                    <img src='images/flownav.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function flownav_start() {
                      document.getElementById('flownav_image').style.opacity = "1";
                    }

                    function flownav_stop() {
                      document.getElementById('flownav_image').style.opacity = "0";
                    }
                    flownav_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="">
                    <span class="papertitle">FlowNav: Learning Efficient Navigation Policies via Conditional Flow Matching</span>
                  </a>
                  <br>
                  <a href="https://samirangode.github.io/">Samiran Gode</a>*,
                  <strong>Abhijeet Nayak*</strong>                  
                  <a href="https://www.utn.de/person/wolfram-burgard-2/">Wolfram Burgard</a>

                  <br>
                  <em>Learning Effective Abstractions for Planning (LEAP) Workshop, CoRL</em>, 2024 <br>
                  <em>Differentiable Optimization Everywhere: Simulation, Estimation, Learning, and Control (Workshop), CoRL</em>, 2024
                  <br>
                  <!-- <a href="http://ralf.cs.uni-freiburg.de/">project page</a>
                  / -->
                  <a href="https://arxiv.org/abs/2411.09524">arXiv</a>
                  <!-- /
                  <a href="https://github.com/robot-learning-freiburg/RaLF">code</a> -->

                  <p></p>
                  <p>
                    Learning actions for robot navigation using Conditional Flow Matching. 
                    With a faster inference time, FlowNav is ideal for environments with dynamic objects.
                  </p>
                </td>
              </tr>

              <tr onmouseout="ralf_stop()" onmouseover="ralf_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='ralf_video'>
                      <video width=100% height=100% muted autoplay loop>
                        <source src="videos/ralf.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                      </video>
                    </div>
                    <div class="two" id="ralf_image">
                      <img src='images/ralf_1.png' width="100%">
                    </div>
                  </div>
                  <script type="text/javascript">
                    function ralf_start() {
                      document.getElementById('ralf_video').style.opacity = "1";
                      document.getElementById('ralf_image').style.opacity = "0";
                    }

                    function ralf_stop() {
                      document.getElementById('ralf_video').style.opacity = "0";
                      document.getElementById('ralf_image').style.opacity = "1";
                    }
                    ralf_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="http://ralf.cs.uni-freiburg.de/">
                    <span class="papertitle">RaLF: Flow-based Global and Metric Radar Localization in LiDAR Maps</span>
                  </a>
                  <br>
                  <strong>Abhijeet Nayak*</strong>
                  <a href="https://rl.uni-freiburg.de/people/cattaneo">Daniele Cattaneo</a>*,
                  <a href="https://rl.uni-freiburg.de/people/valada">Abhinav Valada</a>

                  <br>
                  <em>International Conference on Robotics and Automation</em>, 2024
                  <br>
                  <a href="http://ralf.cs.uni-freiburg.de/">project page</a>
                  /
                  <a href="https://arxiv.org/abs/2309.09875">arXiv</a>
                  /
                  <a href="https://youtu.be/Ru3LzX6iHVM">video</a>
                  /
                  <a href="https://github.com/robot-learning-freiburg/RaLF">code</a>

                  <p></p>
                  <p>
                    Global and metric localization of radar data on a prior LiDAR map of the environment.
                    Place recognition is used for global localization, whereas optical flow between the 
                    radar image and lidar submap is used for metric localization.
                    Our method outperforms prior methods on unseen datasets.
                  </p>
                </td>
              </tr>


              <tr onmouseout="comp_servo_stop()" onmouseover="comp_servo_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='cs_image'><video width=100% muted autoplay loop>
                        <source src="videos/compositional_servoing.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                      </video>
                    </div>
                    <div class="two" id="im">
                      <img src='images/comp_servo.jpg' width=100%>
                    </div>
                  </div>
                  <script type="text/javascript">
                    function comp_servo_start() {
                      document.getElementById('cs_image').style.opacity = "1";
                      document.getElementById('im').style.opacity = "0";
                    }

                    function comp_servo_stop() {
                      document.getElementById('cs_image').style.opacity = "0";
                      document.getElementById('im').style.opacity = "1";
                    }
                    compo_servo_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://compservo.cs.uni-freiburg.de/">
                    <span class="papertitle"> Compositional Servoing by Recombining Demonstrations
                    </span>
                  </a>
                  <br>
                  <a href="https://lmb.informatik.uni-freiburg.de/people/argusm/">Max Argus*</a>,
                  <strong>Abhijeet Nayak*</strong>,
                  <a href="https://rl.uni-freiburg.de/people/buechner">Martin BÃ¼chner</a>,
                  <a href="https://lmb.informatik.uni-freiburg.de/people/galessos/">Silvio Galesso</a>,
                  <a href="https://rl.uni-freiburg.de/people/valada/">Abhinav Valada</a>,
                  <a href="https://lmb.informatik.uni-freiburg.de/people/brox/index.html">Thomas Brox</a>
                  <br>
                  <em>International Conference on Robotics and Automation</em>, 2024
                  <br>
                  <a href="http://compservo.cs.uni-freiburg.de/">project page</a>
                  /
                  <a href="https://arxiv.org/abs/2310.04271">arXiv</a>
                  /
                  <a href="https://youtu.be/cTXngMrN5CQ">video</a>
                  /
                  <a href="https://github.com/BlGene/flowcontrol/tree/abhijeet_recombination">code</a>

                  <p></p>
                  <p>
                    Demonstrations collected for an object manipulation task can be reused for other tasks.
                    Here, we reuse parts of different demonstrations sequentially to 
                    show that object manipulation skills can be transferred between tasks.

                  </p>
                </td>
              </tr>

              <tr onmouseout="drone_stop()" onmouseover="drone_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/drone.png' width=100%>
                  </div>
                  <script type="text/javascript">
                    function drone_start() {
                      document.getElementById('drone_image').style.opacity = "1";
                    }

                    function drone_stop() {
                      document.getElementById('drone_image').style.opacity = "0";
                    }
                    drone_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://link.springer.com/chapter/10.1007/978-3-031-13324-4_37">
                    <span class="papertitle">Evaluation of Fully-Convolutional One-Stage Object Detection for Drone Detection</span>
                  </a>
                  <br>
                  <strong>Abhijeet Nayak*</strong>,
                  Mondher Bouazizi*,
                  Tasweer Ahmad*,
                  Artur GonÃ§alves</a>,
                  Bastien Rigault</a>,
                  Raghvendra Jain</a>,
                  <a href="https://scholar.google.co.jp/citations?user=Dy8iau4AAAAJ&hl=en">Yutaka Matsuo</a>,
                  <a href="https://scholar.google.com/citations?hl=en&user=ExEodcUAAAAJ&view_op=list_works&sortby=pubdate">Helmut Prendinger</a>
                  <br>
                  <em>Image Analysis and Processing (ICIAP) Workshops</em>, 2022
                  <br>
                  <a href="https://link.springer.com/chapter/10.1007/978-3-031-13324-4_37">paper</a>
                  <p></p>
                  <p>
                    In the Drone-vs-bird detection challenge, we employed the Fully-Convolutional One-Stage (FCOS)
                     network for drone detection. To enhance detection accuracy and minimize false 
                     positives, we applied data augmentation techniques, which strengthened the model's 
                     robustness against drone-like objects. As a result, our improved detection 
                     performance secured us third place in the challenge.                  
                  </p>
                </td>
              </tr>

              <tr onmouseout="loc_stop()" onmouseover="loc_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id="loc_image">
                      <img src='images/relocalization.png' width=100%>
                    </div>
                  </div>
                  <script type="text/javascript">
                    function loc_start() {
                      document.getElementById('loc_image').style.opacity = "1";
                    }

                    function loc_stop() {
                      document.getElementById('loc_image').style.opacity = "1";
                    }
                    loc_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://ieeexplore.ieee.org/abstract/document/9287930">
                    <span class="papertitle">Re-localization for Self-Driving Cars using Semantic Maps</span>
                  </a>
                  <br>
                  <a>Lhilo Kenye</a>,
                  <a>Rishitha Palugulla</a>,
                  <a>Mehul Arora</a>,
                  <a>Bharath Bhat</a>,
                  <a>Rahul Kala</a>,
                  <strong>Abhijeet Nayak</strong>
                  <br>
                  <em>International Conference on Robotic Computing</em>, 2020
                  <br>
                  <a href="https://ieeexplore.ieee.org/abstract/document/9287930">paper</a>
                  <p></p>
                  <p>
                    We propose a vehicle re-localization algorithm that uses a semantic map of the environment for localization.
                    The semantic map consists of landmarks detected along the path of the vehicle.
                  </p>
                </td>
              </tr>


              <table
                style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                  <tr>
                    <td style="padding:0px">
                      <br>
                      <p style="text-align:center;font-size:small;">
                        Stole this website from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>.
                      </p>
                    </td>
                  </tr>
                </tbody>
              </table>
        </td>
      </tr>
  </table>
</body>

</html>